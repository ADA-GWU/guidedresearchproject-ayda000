{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfbfcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/adakilic/anaconda3/lib/python3.10/site-packages (1.12.1)\n",
      "Requirement already satisfied: transformers in /Users/adakilic/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: filelock in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/adakilic/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c34f1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da003689",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e02b9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6849daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a specific sheet from the Excel file into a DataFrame\n",
    "df = pd.read_excel('fomc_statements.xlsx', sheet_name='statements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0af2e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Date', 'Statement'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea2d9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "df['Statement'] = df['Statement'].astype(str)\n",
    "# Text preprocessing\n",
    "df['Statement'] = df['Statement'].apply(lambda x: x.lower()) # convert text to lowercase\n",
    "df['Statement'] = df['Statement'].apply(lambda x: re.sub(r'\\d+', '', x)) # remove numbers\n",
    "df['Statement'] = df['Statement'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x)) # remove punctuation\n",
    "\n",
    "# Loading tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Tokenize the statement column\n",
    "inputs = tokenizer(df['Statement'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6c9c5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Date                                          Statement\n",
      "0  2000-02-02 00:00:00  the federal open market committee voted today ...\n",
      "1  2000-03-21 00:00:00  the federal open market committee voted today ...\n",
      "2  2000-05-16 00:00:00  the federal open market committee voted today ...\n",
      "3  2000-06-28 00:00:00  the federal open market committee at its meeti...\n",
      "4  2000-08-22 00:00:00  the federal open market committee at its meeti...\n",
      "5  2000-10-03 00:00:00  the federal open market committee at its meeti...\n",
      "6  2000-11-15 00:00:00  the federal open market committee at its meeti...\n",
      "7  2000-12-19 00:00:00  the federal open market committee at its meeti...\n",
      "8  2001-01-03 00:00:00  the federal open market committee decided toda...\n",
      "9  2001-01-31 00:00:00  the federal open market committee at its meeti...\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a23a8f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping  NaN values\n",
    "df = df.dropna(subset=['Statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5ed1287",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Statement'] = df['Statement'].apply(lambda x: re.sub(r'<.*?>', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03b330db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Statement'] = df['Statement'].apply(lambda x: re.sub(r'https?://\\S+|www\\.\\S+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12210c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained FinBERT model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "\n",
    "# Tokenize the statement column\n",
    "inputs = tokenizer(df['Statement'].tolist(), truncation=True, padding=True, return_tensors=\"pt\")\n",
    "\n",
    "# Run the model on the inputs\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# Convert the logits to probabilities\n",
    "probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Convert probabilities tensor to numpy array\n",
    "probs_np = probs.detach().numpy()\n",
    "\n",
    "# Create a new DataFrame with dates and probabilities\n",
    "df_results = pd.DataFrame({\n",
    "    'date': df['date'],\n",
    "    'negative_prob': probs_np[:, 0],\n",
    "    'neutral_prob': probs_np[:, 1],\n",
    "    'positive_prob': probs_np[:, 2]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f61677d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
